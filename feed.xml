<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2019-05-28T17:34:05+09:00</updated><id>/</id><title type="html">sysmoon’s blog</title><subtitle>문형권 기술블로그 (sysmoon@sk.com)</subtitle><entry><title type="html">Istio Telemetry (Collecting Metric)</title><link href="/istio-collecting_metrics" rel="alternate" type="text/html" title="Istio Telemetry (Collecting Metric)" /><published>2018-05-28T19:00:00+09:00</published><updated>2018-05-28T19:00:00+09:00</updated><id>/istio-collecting_metrics</id><content type="html" xml:base="/istio-collecting_metrics">&lt;h1 id=&quot;collecting-metric&quot;&gt;Collecting Metric&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;../assets/images/istio/istio_archi.png&quot; alt=&quot;istio architecture&quot; /&gt;&lt;/p&gt;

&lt;p&gt;istio는 각 pods의 Envoy side_car_proxy(Envoy) 에서 생성된 telemery 정보를 Mixer에 통합 수집하여 관리한다.
이 세션에서는 Service Mesh를 위해 자동으로 telemetry 정보를 수집하기 위한 istio congiruation에 대해 알아본다.
마지막 부분에 Service Mesh 안에서 새로운 서비스를 위한 Metric이 활성화 된다.&lt;/p&gt;

&lt;p&gt;Bookinfo sample 어플케이션이 이 task를 위해 예제로 활용되기 때문에 먼저 Bookinfo App 이 먼저 배포되어 있어야 한다.&lt;/p&gt;

&lt;h2 id=&quot;before-you-begin&quot;&gt;Before you begin&lt;/h2&gt;
&lt;p&gt;사용하고 있는 K8S 클러스터에 Istio를 설치하고, App을 배포한다. 이 task는 Minxer가 default configuration (–configDefaultNamespace=istio-system) 으로 설정되어 있다고 가정한다.
만약 다른 설정값을 사용하고 있다면, 위 설정으로 업데이트해야 한다.&lt;/p&gt;

&lt;h2 id=&quot;collecting-new-metrics&quot;&gt;Collecting new metrics&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;새로운 metric 정보를 수집하기 위해 YAML 파일을 적용하면, istio는 필요한 리소스를 생성하고, metic 정보를 자동으로 수집한다.
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl apply -f samples/bookinfo/telemetry/metrics.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;istio &amp;gt;= 1.1.2 일 경우, 아래 yaml configuration 적용 필요&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl apply -f samples/bookinfo/telemetry/metrics-crd.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Bookinfo (sample application)에 traffic 전송한다. Bookinfo App의 경우, browser를 통해 http://$GATEWAY_URL/productpage 브라우징 하거나, 아래와 같이 curl을 이용하여 http request 수행한다.
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl http://$GATEWAY_URL/productpage
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;참고로 minikube 환경에서 GATEWAY_URL을 설정하기 위한 방법을 아래 방법을 사용하면 된다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export INGRESS_HOST=$(minikube ip)  
export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name==&quot;http2&quot;)].nodePort}')  
export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name==&quot;https&quot;)].nodePort}')  
export GATEWAY_URL=$INGRESS_HOST:$INGRESS_PORT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ol&gt;
  &lt;li&gt;새로운 metric 정보가 생생/수집 되고 있는지 확인하다. 쿠버네티스 환경에서 Prometheus를 위한 port-forwarding setup을 위해 다음과 같은 명령어를 실행한다.
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; kubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=prometheus -o jsonpath='{.items[0].metadata.name}') 9090:9090 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;새로운 metric value 값 확인을 위해 &lt;a href=&quot;http://localhost:9090/graph?g0.range_input=1h&amp;amp;g0.expr=istio_double_request_count&amp;amp;g0.tab=1&quot;&gt;Prometheus UI&lt;/a&gt; 웹브라우저 접속하여 확인한다. 위 제공된 링크는 Prometheus UI 페이지를 오픈하고, istio_double_request_count metric 값을 쿼리를 실행한다. Console Tab 안에 아래 테이블에 표시된 entry 정보는 다음과 유사하다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;istio_double_request_count{destination=&quot;details-v1&quot;,instance=&quot;172.17.0.12:42422&quot;,job=&quot;istio-mesh&quot;,message=&quot;twice the fun!&quot;,reporter=&quot;client&quot;,source=&quot;productpage-v1&quot;}   8
istio_double_request_count{destination=&quot;details-v1&quot;,instance=&quot;172.17.0.12:42422&quot;,job=&quot;istio-mesh&quot;,message=&quot;twice the fun!&quot;,reporter=&quot;server&quot;,source=&quot;productpage-v1&quot;}   8
istio_double_request_count{destination=&quot;istio-policy&quot;,instance=&quot;172.17.0.12:42422&quot;,job=&quot;istio-mesh&quot;,message=&quot;twice the fun!&quot;,reporter=&quot;server&quot;,source=&quot;details-v1&quot;}   4
istio_double_request_count{destination=&quot;istio-policy&quot;,instance=&quot;172.17.0.12:42422&quot;,job=&quot;istio-mesh&quot;,message=&quot;twice the fun!&quot;,reporter=&quot;server&quot;,source=&quot;istio-ingressgateway&quot;}   4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;더 많은 metric value 값을 Prometheus에서 쿼리하기 위해 &lt;a href=&quot;https://istio.io/docs/tasks/telemetry/metrics/querying-metrics/&quot;&gt;Querying Istio Metrics&lt;/a&gt; 을 참고한다.&lt;/p&gt;

&lt;h1 id=&quot;understanding-the-metrics-configuration&quot;&gt;Understanding the metrics configuration&lt;/h1&gt;
&lt;p&gt;이번 task 에서는 service mesh 안에서 발생하는 모든 트랙픽에 대한 새로운 metric 정보를 자동으로 report &amp;amp; generate 하기 위한 설정을 Mixer에 추가했다.
추가된 설정은 Mixer 기능의 3가지 부분을 컨트롤 하도록 했다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;istio attribute 에서 instance(이 예제에서는 metric 값)을 생성&lt;/li&gt;
  &lt;li&gt;생성된 인스터스를 processing 할 수 있는 handlers 생성&lt;/li&gt;
  &lt;li&gt;일련의 Rule Set 규칙에 따라 인스턴스를 handlers에 저장&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;metric configuration은 Mixer가 Prometheus에서 metric value 값을 전달하도록 명시합니다. 이것은 3가지 블럭 구성을 사용합니다. instance configuration, handler configuration, and rule configuration.&lt;/p&gt;

&lt;p&gt;구성의 종류 : instance 스탠자는 doublerequestcount라는 새 메트릭에 대해 생성 된 메트릭 값 (또는 인스턴스)에 대한 스키마를 정의합니다. 이 인스턴스 설정은, Mixer에게, Envoy에 의해보고되는 속성 (및 Mixer 자체에 의해 생성되는 속성)에 근거 해, 임의의 요구에 대해서 메트릭스 치를 생성하는 방법을 지시합니다.&lt;/p&gt;

&lt;p&gt;doublerequestcout 에 대한 각각의 instance에 대해, configuration은 Mixer가 각 instance 에 대해 값 2를 지원하도록 명시한다.&lt;/p&gt;

&lt;p&gt;각각의 doublerequestcount에 대한 dimensions 구성은 구체화 되어있다. Dimesions은 다른 필요성과 질의 방향에 따라 metric 데이터를 자르고, 수집하고, 분석하는 방법을 제공한다.&lt;/p&gt;

&lt;p&gt;이러한 설정은 Mixer가 이러한 속성값과 일반적인 값을 기반으로 한 dimensions 값을 생성하도록 지시한다. 예를 들면 source dimension의 경우 새로운 설정은 value 값이 source.workload.name 속성값을 가지도록 요청한다. 만약 속성값이 생성되지 않으면, rule은 Mixer가 unkown default 값을 사용하도록 한다. message dimenstion에 대해 일반적인 값 “tview the fun!” 이 모든 인스턴스에 대해 사용될 것이다.&lt;/p&gt;

&lt;p&gt;handler 구성 블록은 &lt;em&gt;doublehandler&lt;/em&gt; 라는 hander를 정의한다. handler는 Prometheus adapter code가 어떻게 수신한 metric instance를 Prometheus backend에서 프로레싱할 수 있도록 Promethes-formatted value 값으로 변경하여 전달하는지를 명시한다. 이 구성은 &lt;em&gt;double_request_count&lt;/em&gt; 이름의 새로운 Prometheus Metric 이름을 명시했다. Prometheus adapter는 &lt;em&gt;istio_&lt;/em&gt; 네임스페이스를 접두어로 붙였는데, 이 metric 정보는 Prometheus 에서 &lt;em&gt;istio_double_request_count&lt;/em&gt; 로 보여질 것이다. metric은 &lt;em&gt;doublerequestcount&lt;/em&gt; instances를 위한 3가지 라벨 매칭 dimention 설정을 가지고 있다.&lt;/p&gt;

&lt;p&gt;믹서 인스턴스는 instance_name 매개 변수를 통해 Prometheus 메트릭과 일치합니다. instance_name은 Mixer instances(exmaple: doublerequestcount.instance.istio-system)을 위해 fully-qualified 이름이어야 합니다.&lt;/p&gt;

&lt;p&gt;rule 구성은 새로운 rule 이름 &lt;em&gt;doubleprom&lt;/em&gt; 정의합니다. 이 rule은 Mixer가 모든 doublerequestcount instance를 &lt;em&gt;doublehandler&lt;/em&gt; handler로 전송하도록 설정합니다. rule 안에 match 절이 없기 때문에 그리고 rule은 네임스페이스(istio-system) 안에서 default configuration 설정되었기 때문에 rule은 service mesh 안에 있는 모든 request에 대해 동작한다.&lt;/p&gt;</content><author><name>sysmoon</name></author><category term="istio" /><summary type="html">Collecting Metric</summary></entry><entry><title type="html">Azure IoTHub</title><link href="/azure-iotedge" rel="alternate" type="text/html" title="Azure IoTHub" /><published>2018-05-08T19:00:00+09:00</published><updated>2018-05-08T19:00:00+09:00</updated><id>/azure-iotedge</id><content type="html" xml:base="/azure-iotedge">&lt;h1 id=&quot;introduce&quot;&gt;Introduce&lt;/h1&gt;
&lt;p&gt;Azure IotHub를 이용하여 다양한 IoT 디바이스를 관리하고, Telemetry 정보를 수집하여 Power BI로 분석 가능하다. 또한 IoT 디바이스를 Edge Computing으로 활용하여 IotHub 런타임 위에 ML Conference가 가능한 컨테이너를 내려 다양한 고급 분석이 가능하다.&lt;/p&gt;

&lt;h1 id=&quot;agenda&quot;&gt;Agenda&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Setup Dev Environment
    &lt;ul&gt;
      &lt;li&gt;IotHub&lt;/li&gt;
      &lt;li&gt;DPS (Device Provisioning Service)&lt;/li&gt;
      &lt;li&gt;Cosmos DB&lt;/li&gt;
      &lt;li&gt;ASA (Azure Streaming Analytics)&lt;/li&gt;
      &lt;li&gt;Storage&lt;/li&gt;
      &lt;li&gt;Etc&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Setup Rasp Pi&lt;/li&gt;
  &lt;li&gt;Run D2C message application on Rasp&lt;/li&gt;
  &lt;li&gt;Provision a device using Azure IoT DPS (X.509 Individual Enrollment)&lt;/li&gt;
  &lt;li&gt;D2C Message, Azure Streaming Analytics, Data Storage/DB&lt;/li&gt;
  &lt;li&gt;Custom Vision Edge module deployment&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;setup-dev-environment&quot;&gt;Setup Dev Environment&lt;/h1&gt;

&lt;h2 id=&quot;prerequsite&quot;&gt;Prerequsite&lt;/h2&gt;
&lt;p&gt;hands-on을 위해 개발 PC에 아래 도구들은 미리 설치한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Visual Studio Code Extension
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://marketplace.visualstudio.com/items?itemName=vsciot-vscode.azure-iot-toolkit&quot;&gt;azure-iot-toolkit&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://marketplace.visualstudio.com/items?itemName=vsciot-vscode.azure-iot-edge&quot;&gt;azure-iot-edge&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://marketplace.visualstudio.com/items?itemName=PeterJausovec.vscode-docker&quot;&gt;docker&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://aka.ms/aziotdevexp&quot;&gt;device exploerer&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://azure.microsoft.com/ko-kr/features/storage-explorer/&quot;&gt;Storage Explorer&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.docker.com/install/&quot;&gt;Docker CE&lt;/a&gt;&lt;br /&gt;
Install Docker Community Edition (CE). Don’t sign in Docker Desktop after Docker CE installed.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;create-azure-resources&quot;&gt;Create Azure Resources&lt;/h2&gt;

&lt;h3 id=&quot;iothub&quot;&gt;IotHub&lt;/h3&gt;
&lt;h3 id=&quot;dps&quot;&gt;DPS&lt;/h3&gt;
&lt;h3 id=&quot;asa-azure-streaming-analytics&quot;&gt;ASA (Azure Streaming Analytics)&lt;/h3&gt;
&lt;h3 id=&quot;cosmos-db&quot;&gt;Cosmos DB&lt;/h3&gt;
&lt;h3 id=&quot;storage-account&quot;&gt;Storage Account&lt;/h3&gt;

&lt;h1 id=&quot;setup-rasp-pi&quot;&gt;Setup Rasp Pi&lt;/h1&gt;

&lt;h3 id=&quot;install-the-raspbian-operating-system-for-pi&quot;&gt;Install the Raspbian operating system for Pi&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Download Raspbian.
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://downloads.raspberrypi.org/raspbian/images/raspbian-2017-07-05/&quot;&gt;Download Raspbian Stretch&lt;/a&gt; (the .zip file)&lt;/li&gt;
      &lt;li&gt;Extract the Raspbian image to a folder on your computer.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Install Raspbian to the microSD card.
    &lt;ul&gt;
      &lt;li&gt;Download and install the Etcher SD card burner utility&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Run Etcher and select the Raspbian image that you extracted in step 1.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Select the microSD card drive. Etcher may have already selected the correct drive.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Click Flash to install Raspbian to the microSD card.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Remove the microSD card from your computer when installation is complete. It’s safe to remove the microSD card directly because Etcher automatically ejects or unmounts the microSD card upon completion.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Insert the microSD card into Pi.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;enable-ssh-and-i2c&quot;&gt;Enable SSH and I2C&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Connect Pi to the monitor, keyboard, and mouse. 2. Start Pi and then sign into Raspbian by using pi as the user name and raspberry as the&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;password.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Click the Raspberry icon &amp;gt; Preferences &amp;gt; Raspberry Pi Configuration.
&lt;img src=&quot;../assets/images/iothub/rasp_conf01.png&quot; alt=&quot;iothub_conf&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;On the Interfaces tab, set I2C and SSH to Enable, and then click OK. If you don’t have
&lt;img src=&quot;../assets/images/iothub/rasp_conf02.png&quot; alt=&quot;iothub_conf&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;physical sensors and want to use simulated sensor data, this step is optional.&lt;/p&gt;

&lt;p&gt;Connect the sensor to Pi (+) 방향 : 3.3V PWR
&lt;img src=&quot;../assets/images/iothub/rasp_conf_gpo01.png&quot; alt=&quot;rasp_conf_gpo01&quot; /&gt;
&lt;img src=&quot;../assets/images/iothub/rasp_conf_gpo02.png&quot; alt=&quot;rasp_conf_gpo02&quot; /&gt;&lt;/p&gt;

&lt;p&gt;중간 : GPIO 4&lt;/p&gt;

&lt;p&gt;(-) 방향 : GND&lt;/p&gt;

&lt;p&gt;Connect Pi to the network&lt;/p&gt;

&lt;p&gt;Note IP address of your Pi.&lt;/p&gt;

&lt;h1 id=&quot;run-d2c-message-application-on-rasp&quot;&gt;Run D2C message application on Rasp&lt;/h1&gt;
&lt;p&gt;rasp pi -&amp;gt; IotHub 로 센서데이터를 전송하기 위한 샘플 예제코드는 아래 git url을 통해 다운로드 가능하다.  &lt;a href=&quot;https://github.com/Azure-Samples/azure-iot-samples-python&quot;&gt;azure-iot-samples-python&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;```
git clone https://github.com/Azure-Samples/azure-iot-samples-python&lt;/p&gt;</content><author><name>문형권</name></author><category term="azure" /><category term="iothub" /><summary type="html">Introduce Azure IotHub를 이용하여 다양한 IoT 디바이스를 관리하고, Telemetry 정보를 수집하여 Power BI로 분석 가능하다. 또한 IoT 디바이스를 Edge Computing으로 활용하여 IotHub 런타임 위에 ML Conference가 가능한 컨테이너를 내려 다양한 고급 분석이 가능하다.</summary></entry><entry><title type="html">Azure Machine Learning Architecture</title><link href="/azure-ml-archi" rel="alternate" type="text/html" title="Azure Machine Learning Architecture" /><published>2018-05-08T19:00:00+09:00</published><updated>2018-05-08T19:00:00+09:00</updated><id>/azure-ml-archi</id><content type="html" xml:base="/azure-ml-archi">&lt;h1 id=&quot;azure-ml-architecture&quot;&gt;Azure ML Architecture&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;../assets/images/az_ml_archi.png&quot; alt=&quot;Azure ML Architecture&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Azure ML Architecture는 기본적으로 BigData 수집/저장/분석을 위한 플랫폼과 큰 차이가 없다.
분석을 위한 플랫폼에 ML을 위한 파이프라인이 들어가 있는 차이점이 있을 뿐이다.
따라서 전체적인 구조는 데이터 수집/저장(실시간/배치) -&amp;gt; 데이터 탐색 -&amp;gt; ML 모델 개발 -&amp;gt; ML 서비스 운영(DW/BI) -&amp;gt; 모니터링 구조로 되어있다.&lt;/p&gt;

&lt;h2 id=&quot;1-데이터-수집-batch-job&quot;&gt;1. 데이터 수집 (Batch Job)&lt;/h2&gt;
&lt;p&gt;원천 데이터가 있는 Data WareHouse (DataBase, Hadoop, File ..) 에서 Batch Job으로 데이터를 로딩한 후, 
ETL Processing을 통해 데이터에 대한 정제작업을 하여 Data Lake or Blob Storage에 저장할 한다.&lt;/p&gt;

&lt;h2 id=&quot;2-데이터-수집-realtime-job&quot;&gt;2. 데이터 수집 (Realtime Job)&lt;/h2&gt;
&lt;p&gt;실시간성 데이터 (Social Network, Network Security Info, Applcation Log) 의 경우 Event Hubs, Kafka와 같은 Pub/Sub 구조의 대용량 로그 큐잉 시스템에 저장하고, 이후 Azure DATABRICS, HDINSIGHT, Stream Analytics와 같은 다양한 종류의 분석 플랫폼을 Consumer로 활용하여 ML 데이터로 활용하기 위한 ETL Processing 이 가능하다. 이후 데이터는 다시 분석용 다양한 종료의 분석용 DB(Cosmos DB, RDB, Redis)에 저장하여, 빅데이터 분석 플랫폼에서 BI를 위한 데이터로 활용하거나, Data Warehouse (Data Lake, Blob Storage)에 저장하여 ML을 위한 데이터 용도로 활용한다.&lt;/p&gt;

&lt;h2 id=&quot;3-데이터-탐색&quot;&gt;3. 데이터 탐색&lt;/h2&gt;
&lt;p&gt;2번 과정에 의해 정제된 데이터는 데이터의 포맷과 활용 용도에 따라 NoSQL, Redis 등 다양한 DB에 저장될 수 있고,
Data Lake, Blob Storage와 같은 형태의 Storage 공간에도 저장될 수 있다. 이러한 다양한 데이터 소스를 통해 데이터를 탐색하여 가져온 후, 주요 KPI 항목에 대한 차트를 대시보드 형태로 꾸며 대시보드를 구성하야 BI 도구로 활용할 수 있고, ML 모델 개발을 위한 데이터로도 활용 가능하다.&lt;/p&gt;

&lt;h2 id=&quot;4-ml-모델-개발&quot;&gt;4. ML 모델 개발&lt;/h2&gt;
&lt;p&gt;Azure는 다양한 데이터 소스를 가져와서 ML 모델을 쉽게 개발할 수 있는 AML(Azure ML) 서비스를 제공하고 있다. ML 모델 개발에 필요한 언어, 도구, 파이프라인 설계 등을 쉽게 할 수 있고, 특히 python 언어를 활용하여 3번 과정에서 탐색한 데이터를 Traning 데이터로 활용하여 모델을 만들고, Expreiment 하고, 모델을 Dockerizing 하여 컨테이너 형태로 원하는 타켓에 배포하기 위한 각 과정을 ML 파이프라인으로 설계가 가능하다.&lt;/p&gt;

&lt;h2 id=&quot;5-ml-모델-배포&quot;&gt;5. ML 모델 배포&lt;/h2&gt;
&lt;p&gt;생성된 ML 모델은 다양한 프레임워크(Tensorflow, Pytorch, Keras..)를 통해 다양한 컴퓨팅 자원(Kubernetes, IoT Edge, FPGA, ML Server, ML Studio Web Service, On-Premise ML Servers…)에 Transfer Learning 되고, Realtime or Batch Job을 통해 들어온 데이터를 Infcluence 한다. Realtime 연계를 위해서는 실시간 수집한 데이터를 기반으로 다양한 Serverless 컴퓨팅 자원(Stream Analytics, Service Fabric, Functions, Logic Apps) 활용이 가능하고, Batch 연계를 위해서는 Azure Databricks, SQL Data 도구를 활용 가능하다.
Realtime or Batch 연계를 통해 ML Confluence 된 데이터 결과물들은 비지니스 앱, Analytics 도구 등 다양한 형태와 연동하여 ML 서비스가 가능하다.&lt;/p&gt;</content><author><name>문형권</name></author><category term="azure" /><category term="ml" /><summary type="html">Azure ML Architecture</summary></entry><entry><title type="html">Azure Machine Learning Reference Site</title><link href="/azure-ml-tech-docs" rel="alternate" type="text/html" title="Azure Machine Learning Reference Site" /><published>2017-07-27T19:00:00+09:00</published><updated>2017-07-27T19:00:00+09:00</updated><id>/azure-ml-tech-docs</id><content type="html" xml:base="/azure-ml-tech-docs">&lt;h1 id=&quot;readme&quot;&gt;Readme&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;DevOps
    &lt;ul&gt;
      &lt;li&gt;Auzre ML, DevOps를 활용하여 데이터 분석 플랫폼 구축&lt;/li&gt;
      &lt;li&gt;샘플 데이터 &amp;amp; 모델 기반으로 DevOps for AI 빌드/릴리즈 파이프라인 설계&lt;/li&gt;
      &lt;li&gt;Model별 버전 관리&lt;/li&gt;
      &lt;li&gt;Model 버전별 precision/recall 결과 비교하여 우수한 Model 자동 배포&lt;/li&gt;
      &lt;li&gt;Azure DevOps 이용하여 신규버전 Container 생성(ACR), 이후 IoT Edge 배포&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Azure ML Service
    &lt;ul&gt;
      &lt;li&gt;Cloud 환경에서 Data + DL Model 학습 (object detection)&lt;/li&gt;
      &lt;li&gt;DL Model Test dataset 활용하여 precision/recall 등 지표에 대한 계산/표시&lt;/li&gt;
      &lt;li&gt;모델 선정 및 Model Container 생성 (versioning)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Iot Edge 연동
    &lt;ul&gt;
      &lt;li&gt;Vision AI Dev Kit Camera에 Model Container 배포&lt;/li&gt;
      &lt;li&gt;Image와 Prediction한 결과를 Cloud로 전송하여 live prediction 결과 취합&lt;/li&gt;
      &lt;li&gt;Bounding box와 confidence score 값 저장&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;개요&quot;&gt;개요&lt;/h1&gt;
&lt;p&gt;기본 기술문서: https://docs.microsoft.com/en-us/azure/machine-learning/service/&lt;/p&gt;

&lt;p&gt;주요 개념: https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-azure-machine-learning-architecture&lt;/p&gt;

&lt;p&gt;모델관리 개념: https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-model-management-and-deployment&lt;/p&gt;

&lt;p&gt;Pipeline 개념: https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-ml-pipelines&lt;/p&gt;

&lt;p&gt;보안 관련 접근: https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-enterprise-security&lt;/p&gt;

&lt;h1 id=&quot;hackfest&quot;&gt;Hackfest&lt;/h1&gt;

&lt;p&gt;아래 hackfest 사이트를 통해 Azure ML의 전반적인 사용법을 익힐 수 있습니다.
https://github.com/Azure/LearnAI_Azure_ML&lt;/p&gt;

&lt;h1 id=&quot;샘플&quot;&gt;샘플&lt;/h1&gt;

&lt;p&gt;샘플 사용방법: https://docs.microsoft.com/en-us/azure/machine-learning/service/samples-notebooks&lt;/p&gt;

&lt;p&gt;깃허브: https://github.com/Azure/MachineLearningNotebooks&lt;/p&gt;

&lt;p&gt;(여기에 아래 거의 모든 기능들에 대한 샘플이 있으니 가장 유용할 것으로 판단.)&lt;/p&gt;

&lt;p&gt;기능별 상세 가이드는 How-to guides (방법 가이드) 이하 항목으로 나온다.
직관적으로 되어 있어서 원하시는 단계를 찾으시면 되며, 몇 가지만 소개하면 다음과 같습니다:&lt;/p&gt;

&lt;p&gt;개발환경: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-environment&lt;/p&gt;

&lt;p&gt;DataPrep SDK를 이용한 데이터가공: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-transform-data&lt;/p&gt;

&lt;p&gt;Datastore: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-access-data&lt;/p&gt;

&lt;p&gt;원격수행: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets&lt;/p&gt;

&lt;p&gt;Tensorflow 기본방식: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-tensorflow&lt;/p&gt;

&lt;p&gt;Hyperparameter Tuning: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters&lt;/p&gt;

&lt;p&gt;Automated ML: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train&lt;/p&gt;

&lt;p&gt;ONNX: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-build-deploy-onnx&lt;/p&gt;

&lt;p&gt;배포: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-deploy-and-where&lt;/p&gt;

&lt;p&gt;실시간 추론: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-consume-web-service&lt;/p&gt;

&lt;p&gt;배치 추론: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-run-batch-predictions&lt;/p&gt;

&lt;p&gt;모니터: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-enable-app-insights&lt;/p&gt;

&lt;p&gt;쿼터관리: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas&lt;/p&gt;

&lt;h1 id=&quot;sdk&quot;&gt;SDK&lt;/h1&gt;
&lt;p&gt;Azure ML SDK (설치방법 포함): https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py&lt;/p&gt;

&lt;p&gt;Dataprep SDK: https://docs.microsoft.com/en-us/python/api/overview/azure/dataprep/intro?view=azure-dataprep-py&lt;/p&gt;

&lt;p&gt;Monitoring SDK: https://docs.microsoft.com/en-us/python/api/overview/azure/monitoring/intro?view=azureml-monitoring-py&lt;/p&gt;

&lt;h1 id=&quot;etc&quot;&gt;ETC&lt;/h1&gt;
&lt;p&gt;릴리즈 노트: https://docs.microsoft.com/en-us/azure/machine-learning/service/azure-machine-learning-release-notes&lt;/p&gt;

&lt;p&gt;가격체계: https://azure.microsoft.com/ko-kr/pricing/details/machine-learning-service/&lt;/p&gt;

&lt;p&gt;가장 빠른 방법은 아래의 Tutorial 아래에 있는 4개의 샘플을 직접 수행&lt;/p&gt;

&lt;p&gt;MNIST 데이터로 1. 모델 생성, 2. 모델 배포&lt;/p&gt;

&lt;p&gt;NYC Taxi 데이터로 1. 데이터 가공, 2. Automated ML로 모델 생성&lt;/p&gt;

&lt;p&gt;https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-train-models-with-aml&lt;/p&gt;</content><author><name>문형권</name></author><category term="azure" /><category term="ml" /><summary type="html">Readme DevOps Auzre ML, DevOps를 활용하여 데이터 분석 플랫폼 구축 샘플 데이터 &amp;amp; 모델 기반으로 DevOps for AI 빌드/릴리즈 파이프라인 설계 Model별 버전 관리 Model 버전별 precision/recall 결과 비교하여 우수한 Model 자동 배포 Azure DevOps 이용하여 신규버전 Container 생성(ACR), 이후 IoT Edge 배포 Azure ML Service Cloud 환경에서 Data + DL Model 학습 (object detection) DL Model Test dataset 활용하여 precision/recall 등 지표에 대한 계산/표시 모델 선정 및 Model Container 생성 (versioning) Iot Edge 연동 Vision AI Dev Kit Camera에 Model Container 배포 Image와 Prediction한 결과를 Cloud로 전송하여 live prediction 결과 취합 Bounding box와 confidence score 값 저장 개요 기본 기술문서: https://docs.microsoft.com/en-us/azure/machine-learning/service/</summary></entry></feed>